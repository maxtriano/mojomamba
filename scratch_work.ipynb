{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[3163445217, 524636540, 4176527650, 3125866584]], dtype=uint32, shape=4)\n"
     ]
    }
   ],
   "source": [
    "from tensor import Tensor, TensorSpec, TensorShape\n",
    "from utils.index import Index\n",
    "from algorithm import vectorize\n",
    "from sys.info import simdwidthof\n",
    "from random import rand\n",
    "import math\n",
    "\n",
    "let input_ids = rand[DType.uint32](4)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor([[0.19650378823280334, 0.14129260182380676, 0.66934406757354736, 0.80183345079421997]], dtype=float32, shape=4)\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement\n",
    "fn get_embedding(input_ids: Tensor[DType.uint32]) -> Tensor[DType.float32]:\n",
    "    # input_ids:  Tensor of shape (b, 1)\n",
    "    # return:     Tensor of shape (b, 1, d_model)\n",
    "    let EMBEDDING_DIM = 4\n",
    "    return rand[DType.float32](EMBEDDING_DIM)\n",
    "\n",
    "print(get_embedding(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this\n",
    "fn compute_layer(input: Tensor[DType.float32]) -> Tensor[DType.float32]:\n",
    "    # return a random f32 tensor for now\n",
    "    return rand[DType.float32](input.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn RMS_norm(input: Tensor[DType.float32]) -> Tensor[DType.float32]:\n",
    "    var mean: Float32 = 0.0\n",
    "    var squares = Tensor[DType.float32](input.shape())\n",
    "    var output = Tensor[DType.float32](input.shape())\n",
    "    alias simd_float32_width: Int = simdwidthof[DType.float32]()\n",
    "    \n",
    "    # Vectorized squaring of input\n",
    "    @parameter\n",
    "    fn square_tensor[simd_float32_width: Int](idx: Int) -> None:\n",
    "        squares.simd_store[simd_float32_width]\n",
    "                (idx, math.pow(input.simd_load[simd_float32_width](idx), 2))\n",
    "    vectorize[simd_float32_width, square_tensor](input.num_elements())\n",
    "\n",
    "    # Sum up squares\n",
    "    @parameter\n",
    "    fn sum_squares[simd_float32_width: Int](idx: Int) -> None:\n",
    "        mean += squares.simd_load[simd_float32_width](idx).reduce_add()\n",
    "    vectorize[simd_float32_width, sum_squares](squares.num_elements())\n",
    "\n",
    "    mean /= squares.num_elements()\n",
    "    \n",
    "    let rms: Float32 = math.sqrt(mean)\n",
    "    @parameter\n",
    "    fn divide_by_rms[simd_float32_width: Int](idx: Int) -> None:\n",
    "        output.simd_store[simd_float32_width](idx, input.simd_load[simd_float32_width](idx) / rms)\n",
    "    vectorize[simd_float32_width, divide_by_rms](output.num_elements())\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this\n",
    "fn lm_head(input: Tensor[DType.float32]) -> Tensor[DType.float32]:\n",
    "    # return a random f32 tensor for now\n",
    "    return rand[DType.float32](input.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this\n",
    "fn forward_pass(input_ids: Tensor[DType.uint32]) -> Tensor[DType.float32]:\n",
    "    let num_layers = 2\n",
    "    var x = get_embedding(input_ids)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        x = compute_layer(x)\n",
    "            \n",
    "    let normalized = RMS_norm(x)\n",
    "    let logits = lm_head(normalized)\n",
    "\n",
    "    return logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mojo",
   "language": "mojo",
   "name": "mojo-jupyter-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mojo"
   },
   "file_extension": ".mojo",
   "mimetype": "text/x-mojo",
   "name": "mojo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
